{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import RL\n",
    "from taxi_mdp import TaxiMDP\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), '..', 'Data')\n",
    "neighborhoods = pickle.load(open(os.path.join(data_dir, \"neighorhoods.p\"), \"rb\"))\n",
    "driver_areas = pickle.load(open(os.path.join(data_dir, \"driver_areas.p\"), \"rb\"))\n",
    "change_pairs = pickle.load(open(os.path.join(data_dir, \"change_pairs.p\"), \"rb\"))\n",
    "taxi_data = pd.read_csv(os.path.join(data_dir, 'taxi_data.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy(mdp, driver=None, data=None):\n",
    "    \"\"\"Finding the policy for the agent.\n",
    "\n",
    "    :param mdp: MDP object created for some set of taxi drivers.\n",
    "    :param driver: Driver id.\n",
    "    :param data: Data including the driver data.\n",
    "\n",
    "    :return: N, the policy for the driver.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(driver, tuple):\n",
    "        data = data.loc[data['hack_license'].isin(driver)]\n",
    "    else:\n",
    "        data = data.loc[data['hack_license'] == driver]\n",
    "\n",
    "    data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])\n",
    "    data['date'] = data['pickup_datetime'].apply(lambda x: x.date())\n",
    "\n",
    "    data['cum_rewards'] = pd.Series([None for row in xrange(len(data))], index=data.index)\n",
    "\n",
    "    # Tracking the daily cumulative rewards at each transaction.\n",
    "    data['cum_rewards'] = data.groupby(['hack_license', 'date'])['profit'].cumsum()\n",
    "\n",
    "    # Label indicating what reward interval earnings are at following a transaction.\n",
    "    data['reward_interval'] = data['cum_rewards'].apply(lambda y: mdp.reward_intervals.index(filter(lambda x: x[0] <= y < x[1], \n",
    "                                                                                                     mdp.reward_intervals)[0]))\n",
    "\n",
    "    data['next_trip_area'] = data.groupby(['hack_license', 'date'])['start_trip_area'].shift(-1)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Starting and ending areas of policy decision following each transaction.\n",
    "    data['start_choice'] = data['end_trip_area'].apply(lambda x: mdp.mapping[x])\n",
    "    data['end_choice'] = data['next_trip_area'].apply(lambda x: mdp.mapping[x])\n",
    "\n",
    "    # Finding the policy for the data.\n",
    "    N = np.zeros((mdp.n, mdp.m))\n",
    "\n",
    "    for state in mdp.X:\n",
    "        state_num = mdp.state2num[state]\n",
    "\n",
    "        # Empty and not in final reward indicates a choice is being made.\n",
    "        if state[1] == 'e' and state[2] != mdp.reward_intervals[-1]:\n",
    "\n",
    "            state_num = mdp.state2num[state]\n",
    "\n",
    "            start_choice = state[0]\n",
    "\n",
    "            reward_interval = mdp.reward_intervals.index(state[2])\n",
    "\n",
    "            final_reward = mdp.reward_intervals.index(mdp.reward_intervals[-1])\n",
    "\n",
    "            for action in mdp.U:\n",
    "                N[state_num, action] = len(data.loc[(data['reward_interval'] == reward_interval) & \n",
    "                                                   (data['start_choice'] == start_choice) & \n",
    "                                                   (data['end_choice'] == action) & \n",
    "                                                   (data['reward_interval'] != final_reward)])\n",
    "        else:\n",
    "            N[state_num, :] = 1/float(len(mdp.U))\n",
    "\n",
    "    empty_rows = np.where(~N.any(axis=1))[0].tolist()\n",
    "\n",
    "    if not empty_rows:\n",
    "        pass\n",
    "    else:\n",
    "        for row in empty_rows:\n",
    "            N[row] = 1\n",
    "\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver ID 2010003240\n",
      "4.28511602664e-05\n",
      "Driver ID 2010002704\n",
      "6.31521704797e-05\n",
      "Driver ID 2010002920\n",
      "3.08040586816e-05\n",
      "Driver ID 2010001271\n",
      "4.16877443215e-05\n",
      "Driver ID 2010007770\n",
      "4.43669538726e-05\n",
      "Driver ID 2010007579\n",
      "2.94281395554e-05\n",
      "Driver ID 2010007519\n",
      "5.20730355049e-05\n",
      "Driver ID 2010003240\n",
      "5.19652735704e-05\n",
      "Driver ID 2010002704\n",
      "5.57930440976e-05\n",
      "Driver ID 2010002920\n",
      "3.20551791333e-05\n",
      "Driver ID 2010001271\n",
      "2.61486997033e-05\n",
      "Driver ID 2010007770\n",
      "5.28543509404e-05\n",
      "Driver ID 2010007579\n",
      "2.10352710894e-05\n",
      "Driver ID 2010007519\n",
      "4.2771833364e-05\n",
      "Driver ID 2010003240\n",
      "5.81923568461e-05\n",
      "Driver ID 2010002704\n",
      "6.88179477493e-05\n",
      "Driver ID 2010002920\n",
      "5.42016850886e-05\n",
      "Driver ID 2010001271\n",
      "6.27083693416e-05\n",
      "Driver ID 2010007770\n",
      "5.16083769071e-05\n",
      "Driver ID 2010007579\n",
      "4.78391639263e-05\n",
      "Driver ID 2010007519\n",
      "4.38555532583e-05\n"
     ]
    }
   ],
   "source": [
    "all_learned_policies = []\n",
    "all_driver_policies = []\n",
    "all_v_errors = []\n",
    "all_percent_opt = []\n",
    "\n",
    "for gamma in [.9, .95, 1]:\n",
    "    learned_policies = []\n",
    "    driver_policies = []\n",
    "    v_errors = []\n",
    "\n",
    "    for driver in driver_areas.keys():\n",
    "        print 'Driver ID', driver\n",
    "        driver_mdp = TaxiMDP(driver, taxi_data, driver_areas[driver].keys(), \n",
    "                             neighborhoods, 20, change_pairs)\n",
    "        states = driver_mdp.states\n",
    "        actions = driver_mdp.actions\n",
    "        driver_mdp.states = driver_mdp.X\n",
    "        driver_mdp.actions = driver_mdp.U\n",
    "        driver_mdp.X = states\n",
    "        driver_mdp.U = actions\n",
    "        model_rl = RL.ModelBasedRL(gamma=gamma)\n",
    "        model_rl.q_value_iteration(driver_mdp)\n",
    "\n",
    "        v_error = model_rl.test_optimal_v(driver_mdp).max()\n",
    "        print v_error\n",
    "\n",
    "        policy_states = [i for i in xrange(driver_mdp.n) if 'e' in states[i] and ~np.isinf(states[i][2]).any()]\n",
    "        mdp_policy = model_rl.policy[policy_states].tolist()\n",
    "        learned_policy = model_rl.policy[policy_states]\n",
    "        learned_policy = learned_policy.reshape(10, -1)\n",
    "\n",
    "        driver_policy = get_policy(driver_mdp, driver, taxi_data)\n",
    "        driver_policy = np.argmax(driver_policy/driver_policy.sum(axis=1, keepdims=True), axis=1)\n",
    "        driver_policy = driver_policy[policy_states].reshape(10, -1)\n",
    "\n",
    "        learned_policies.append(learned_policy)\n",
    "        driver_policies.append(driver_policy)\n",
    "        v_errors.append(v_error)\n",
    "\n",
    "    percent_opt = []\n",
    "    for i in xrange(len(learned_policies)):\n",
    "        size = float(driver_policies[i].shape[0]*driver_policies[i].shape[1])\n",
    "        percent_opt.append((driver_policies[i] == learned_policies[i]).sum()/float(size))\n",
    "        \n",
    "    all_learned_policies.append(learned_policies)\n",
    "    all_driver_policies.append(driver_policies)\n",
    "    all_v_errors.append(v_errors)\n",
    "    all_percent_opt.append(percent_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.3\n",
      "51.7\n",
      "32.2\n",
      "34.1\n",
      "33.3\n",
      "28.6\n",
      "44.7\n"
     ]
    }
   ],
   "source": [
    "for val in all_percent_opt[0]:\n",
    "    print round(val*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n",
      "44.4\n",
      "17.2\n",
      "21.8\n",
      "26.0\n",
      "16.4\n",
      "36.7\n"
     ]
    }
   ],
   "source": [
    "for val in all_percent_opt[1]:\n",
    "    print round(val*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "75.6\n",
      "77.8\n",
      "84.7\n",
      "63.3\n",
      "86.4\n",
      "64.7\n"
     ]
    }
   ],
   "source": [
    "for val in all_percent_opt[2]:\n",
    "    print round(val*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
